데이터 분석을 실기 시험으로는 처음치러서 인상이 깊게 남아서 인지,

이것저것 생각을 해보다가, ADP 실기시험 몇일전에 끝난 빅콘테스트를 

이번 ADP 실기시험과 연결하여 생각을 해보았습니다.



제가 데이터분석 관련 실무를 한 적은 없으나,

관광빅데이터 분석대회와 빅콘테스트 2개의 대회에 참여를 해서 2개의 대회를 비교하고,

개인적인 직장생활의 기획/마케팅 경험으로 판단을 해보면 빅콘테스트가 실무에 가깝다는 느낌이 들어서,



위의 아젠다는 결국 ADP실기시험까지 통과하면 학력이나 경력을 보지 않고,

데이터 분석 과제를 믿고 맡길 수 있는지를 시뮬레이션 한다고 보면 될 것 같습니다.



뭐, 아직 실무 경험은 없어서 틀릴 수 도 있고, 다른 분들의 생각은 어떤지도 궁금합니다.



아무튼, 어제 저녁 위와 같은 도전적인 아젠다가 떠올랐으나, 피곤해서 일단 자고,

오늘 아침에 나오면서 맑은 정신에 한번 생각을 해보았습니다.



(이렇게 굳이 안해도 될 일을 하는 이유는 그래도 가장 권위있는 데이터 분석시험이 

빨리 자리를 잡고, 그 합격자들이 실력을 인정받기를 바라기 때문입니다. 

그래야 산업이 형성되고, 그것이 커지면서 생태계가 완성되어,

많은 사람들이 좋아하는 일을 하며 즐겁게 살 수 있는 방향으로 가는데, 

조금이라도 도움이 될 것 같아서요.)



1. 일단 결론 부터 말씀드리면 "아닌 것 같다"입니다.



    - 이유는 데이터 먼징(munging, 데이터를 분석할 수 있는 형태로 정리하는 것)이나 

       통계분석, 데이터 마이닝 모두 기능성을 테스트 하는데 큰 문제는

       없었고, 제가 보기에도 이정도의 문제를 풀 수 있는 능력을 가지면 빅콘테스트에서 주어진 과제를

       수행할 수 있을 것 같습니다만, 



    - "사용자 정의 함수"를 만들어서 이를 활용하는 능력을 테스트하는 부분이 빠져있다는 생각이 들기 때문입니다.



2. 빅콘테스트는 중랑구의 나들가게의 매출 지수를 주변의 관련 데이터를 활용하여 학습을 시켜 모델을 만들고,

이를 가지고 관악구에 랜덤하게 지정된 5개의 가게의 10월 16일~10월 20일까지의 매출을 맞추는 문제였습니다.

평가방법은 RMSE 였고, 데이터 mash up이 허용되어, 자신이 원하는 데이터를 가져다 쓸 수 있었습니다.



    - 데이터 매쉬업을 위한 데이터 확보는 시험으로 테스트하기는 어려울 것이라서 제외하면,



    - 주변의 시설정보(관공서, 대형마트, 주변의 아파트, 주변의 편의점 등 자영업 매장등을 포함한 중랑구내 시설의

       건물, 매장여부등의 구분과 이름 그리고 위치 정보)가 cross-sectional data 형태로 주어지고, 



    - 이와는 별도로 이들 시설에서 발생되는 카드매출 정보(업종코드별로 구분이 되었고, training용 나들가게의 카드매출 정보도

       포함되어 있음. 즉 나들가게 매출은 카드매출 + 현금매출)와 모바일 통화건수 정보가 각각에서 정한 cell별로, 

       그리고 주변의 지하철역과 버스 정류장의 위치 및 승하차 인원의 정보가 일별 혹은 시간대별로 주어져서,



    - 이들을 잘 연계해서, training용 데이터마트를 주어진 데이터 혹은 본인이 구한 데이터를 연결시키고, 필터링하여 

       "알아서 직접" 만들고, 이를 가지고 모델을 fiiting하고, 주어진 training나들가게의 매출지수 데이터외에는 

       시계열적인 변동을 추정할 만한 근거가 없기 때문에 이를 가지고, cross validation을 통해서 가장 out-of-sample error가

       낮은 모델을 구성한 후, 여기다가 관악구의 유사한 정보를 넣어서 예측을 하는 것 하나와, 



       이들 가게의 일별 매출을 평균하여 이 분기 평균매출을 종속변수로 하고, 선거관리위원회 홈페이지에서 크롤링

       한 세대수 정보 등을 넣은 regression모델로 산출된 예측값을 ensemble하는 전략을 가지고 저는 문제를 풀어 나갔습니다.



3. 빅콘테스트에서 좌표체계를 비교가능한 형태로 변환하는 방법등은 qgis등의 외부 프로그램의 사용이 필요했는데, ADP실기에서는 문자의 엔코딩을 R에서 동작가능한 형태로 바꿔줄 수 있는지를 테스트 하는 문제가 있었기 때문에 



     - 분석에 필요한 "외부 프로그램" 활용이나 과제에 따라 생기는 "현장의 예상치 않았던 소소한 문제"를 해결할 수 있는지를 보는 부분이 있었다고 볼 수 있습니다. 



4. 빅콘테스트에서 매출과 상관이 있는 변수들의 추출을 위해서는 일별, 시간별, 업종코드별로 평균, 최대, 최소 값 등을

나들가게별로 혹은 일별 나들가게별로 추출해서 이들을 가지고 매출 예측모델을 fitting하고, 47개 가게의 leave-one-out cross-validation으로 RMSE가 개선되는지 아닌지를 보면서 모델을 튜닝해 나가야 했는데, (물론 이 경우는 제가 세운 예측 전략을 따른다는 가정하에서 필요한 부분입니다.)



     - 참고로 제가 분석한 바로는, 나들가게 인근 300m이내에 있는 업종코드 200번대의 매출이 발생하는 가게수와 나들가게의

        매출이 56%의 상관관계를 가지고 있었습니다.



ADP실기에서는 추출이 가능한 형태로 데이터를 만들고, sqldf의 group by나 집계함수(sum. count)등을 활용하여 이들을 원하는 행태로 집계하는 문제가 있었고, 모델의 성능을 비교하는 문제가 있었으며, 모델의 지표를 해석하고 feature를 선택하는 문제가 있었기 때문에



     - 분석에 필요한 data munging능력과 적절한 모델을 선택하는 능력, 그리고 feature selection능력을 평가한다고

        볼 수 있습니다.



5. 빅콘테스트에서는 종료 2틀전 아침 9시에 매출 예측의 타겟인 매출 및 방문자 자료를 제외한 관악구의 관련 정보를 제공하고, 하루 후인 다음날 저녁 6시에 대상이 되는 가게 5개의 정보를 제공했으며, 그 다음날 아침 9시에 마감을 하였습니다.



(옛날 주소를 기준으로 주었기 때문에 이들 가게의 좌표를 찾는 것도 수월하게는 안되는 형태로 주소가 제공되었습니다. 아마 "현장"은 다 이럴 것이라서 뭐 할말은 없었습니다. 데이터 분석이라는 일이 쉽지 않다는 것을 일찍이 알고 있었으나, 확실하게 느낄 수 있게 만들어주시더군요. ㅋㅋ )



      - 바로 이 부분이 ADP실기에서 "사용자 정의 함수"를 직접 설계하고, 활용하는 능력을 

         테스트하는 부분이 들어가야 하는 이유라고 저는 생각합니다. 

         한달 넘게 정리를 해서 뭔가를 찾아냈더라도, 이를

         사용자 정의 함수로 batch처리가 가능하도록 정리가 되어 있지않으면, 

         초치기로 output을 내야 하는 입찰과 같은 상황이나  

         위와 같은 마감시간이 정해져 있는 경우 대응이 어려울 수 있습니다.



      - ADP실기 시험에서 이러한 능력을 명시적으로 테스트하는 부분은 없었습니다. 지금 쓰면서 생각해 보니, 

         제가 본 ADP실기 시험정도의 문제를 4시간 만에 완벽하게 푼다면, 위의 문제는 해결할 수 

         있기는 할 것 같습니다만, 명확히 사용자 정의 함수를 만들어서 풀어야 하는 문제는 분명히 없었습니다.



      - 빅 콘테스트에서 저도 이런 스케줄을 알고 있었고, 이에 대비하여 데이터 파일을 중랑구는 끝에 Jr이라고 붙이고,

         관악구 데이터는 Kw라고 붙여서 구분을 할 수 있게하고, 소스만 들어오면 데이터를 필요한 형태로  들어오게 하는 데는 

         문제가 없었습니다.



      - 하지만 위에서 말씀드린 인근 300m이내에 있는 업종코드 200번대(할인점, 슈퍼마켓, 식품잡화 등 이런 생활주변의 잡화

         등을 파는 업종)의 가게 수를 뽑는 사용자정의 함수에(이것외에도 많이 있었습니다. 이런게...)

         제가 아무 생각 없이 sqldf select문내에 ---Jr 이런 것들을 넣어 

         두었던 모양입니다. 뭐, 워낙 많은 trial을 했었고, 유의미한 변수를 만들어보려고, 이것 저것 잡다하게 하다가,

         관악구 주소를 받고 나서도 feature를 뽑아 공식에 반영하라고 엔터만 치면 답이 나오게 만들어 놨다고 생각해서, 

         계속 모델을 테스트하다가 위의 "상관관계 56%짜리 feature"를 찾아 내기는 했습니다만,

         이미 시간은 새벽 4시였습니다. 더 이상 늦으면 제출을 못한다는 생각에,관악구 데이터를 넣고,

         feature 추출을 시작했는데, ---Kw로 된 데이터들로 인해 오류가 나 버렸습니다.



      - 팀으로 하면 이런 문제가 없었을 것이나, 팀 구성능력을 시험으로 테스트하기는 어려울 것입니다.



      - 어떠한 데이터가 들어가도 되도록 만들어 놓았다고 자신을 했는데, 어딘가에 실수가

         있었던 것이었고, 너무 feature를 찾는데 몰입하다가 아주 기본적인 부분을 놓친 실수를 한 것이지요.

         함수의 코딩에 들어가 있는 Jr을 search/replace해서 Kw로 바꾸어볼까 하다가, 

         그러면 또 다른데서 에러가 생길게 분명하고,

         아직 5시간의 여유가 있으니, 눈에 불을 키고 찾으면 고치기는 할 것인데, 겨우 숫자만 낼 수 있고,

         보고서는 생각도 못할 것이고,

         내일 모레가 ADP실기인데, 여기서 2~3시간이라도 잠을 자두지 않고, 완전히 밤을 새버리면 

         체력적으로 문제가 될 것이고, 그래서 남은 준비를 못하면, 

         ADP까지 망칠 수 있기에 Go or Stop을 결정하지 않을 수 없었습니다. 



      - 막상 그렇게 되니, 결정은 빨리 할 수 있었습니다. 마음은 Go였으나, Stop이 합리적인 판단임은 분명하니까요.

         예전 같았으면 열고인데, 이 정도의 자제를 할 수 있게 된 것은 그간의 경험덕분이라고 생각합니다.



      - 아무튼, 그래서 이 연사, "사용자 정의함수를 설계하고, 활용하는 능력"을 테스트해야 한다고 주장하는 바입니다. ㅋ

         



첨언)  텍스트 마이닝 부분은 명확히 빅콘테스트에서 제공한 자료 등을 분석하는데 직접적인 관련은 없으나,

"R까기"의 수준을 넘어서, 단어의 frequency를 문서와 연결시켜 분석하는 능력을 평가할려고 했다는

점에서 실무활용 능력을 평가할 수 있는 수준이라고 생각이 듭니다. 다만, KoNLP가 그나마 제일 좋은 

한글용 패키지인데, R의 tm 등에 비하면 기능이 떨어지는게 아쉬울 뿐이지요.



- 절대 KoNLP를 폄훼하는 것은 아니니, 오해 마시기 바랍니다. 아무런 보상도 없이 이런 수고를 해주신것에 대해서

감사를 드려도 몇번은 더 드려야 하지만, 아직 우리나라의 생태계가 깊지 못하여 아쉽다는 말씀을 드리는 것입니다.

나중에 제가 프로그래밍 공부하고, 그때까지도 더 좋은 것이 안나와있으면 노니 일한다고, 저라도 한번 도전해 보거나,


아니면 나중에 제가 돈이 모아지면 콘테스트과제로 올려 공모라도 했으면 하는 생각입니다.